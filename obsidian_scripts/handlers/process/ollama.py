import re
import os
import time
import requests
from handlers.process.prompts import PROMPTS
import json
from logger_setup import setup_logger
import logging

setup_logger("ollama", logging.DEBUG)
logger = logging.getLogger("ollama")

TIMEOUT = 10

class OllamaError(Exception):
    """Exception sp√©cifique pour les erreurs Ollama"""
    pass

# Fonction pour interroger Ollama et g√©n√©rer des tags √† partir du contenu d'une note
def get_tags_from_ollama(content):
    logger.debug(f"[DEBUG] tags ollama : lancement fonction")
    model_ollama = os.getenv('MODEL_TAGS')
    
    try:
        prompt = PROMPTS["tags"].format(content=content)
    except Exception as e:
            logger.error(f"[ERREUR] prompt : {e}")
            prompt = None
    if prompt:
        try:
            logger.debug(f"[DEBUG] tags ollama : recherche et lancement du prompt")
            response = call_ollama_with_retry(prompt, model_ollama)
            logger.debug(f"[DEBUG] tags ollama : r√©ponse r√©cup√©r√©e : {response}")

            # EXTRACTION DES TAGS VIA REGEX
            match = re.search(r'\{.*?\}', response, re.DOTALL)  # Tente de capturer un objet JSON complet

            if match:
                try:
                    tags_data = json.loads(match.group(0))
                    tags = tags_data.get("tags", [])
                except json.JSONDecodeError as e:
                    logger.error(f"[ERREUR] Impossible de d√©coder le JSON complet : {e}")
                    tags = ["Error parsing JSON"]
            else:
                # Capture uniquement le tableau
                match = re.search(r'\[.*?\]', response, re.DOTALL)
                if match:
                    try:
                        tags = json.loads(match.group(0))
                    except json.JSONDecodeError as e:
                        logger.error(f"[ERREUR] Impossible de d√©coder le tableau : {e}")
                        tags = ["Error parsing JSON"]
                else:
                    logger.warning("[WARN] Aucun JSON ou tableau trouv√© dans la r√©ponse.")
                    tags = ["No tags found"]

            logger.debug(f"[DEBUG] tags ollama : tags extraits : {tags}")
            return tags
        except OllamaError:
            logger.error("[ERROR] Import annul√©.")
            
    else:
        logger.error("[ERREUR] prompt est invalide, impossible d'appeler Ollama")
            
# Fonction pour g√©n√©rer un r√©sum√© automatique avec Ollama
def get_summary_from_ollama(content):
    logger.debug(f"[DEBUG] r√©sum√© ollama : lancement fonction")
    model_ollama = os.getenv('MODEL_SUMMARY')
    prompt = PROMPTS["summary"].format(content=content)
    logger.debug(f"[DEBUG] r√©sum√© ollama : recherche et lancement du prompt")
    
    try:
        response = call_ollama_with_retry(prompt, model_ollama)
        
        
        logger.debug(f"[DEBUG] summary ollama : reponse r√©cup√©r√©")
    # Nettoyage au cas o√π Ollama ajoute du texte autour
        match = re.search(r'TEXT START(.*?)TEXT END', response, re.DOTALL)
        logger.debug(f"[DEBUG] summary ollama : Nettoyage au cas o√π Ollama ajoute du texte autour : {match}")
        if match:
            summary = match.group(1).strip()
            logger.debug(f"[DEBUG] summary ollama : Nettoyage : {summary}")
        else:
            summary = response  # Si pas de balise trouv√©e, retourne la r√©ponse compl√®te
            logger.debug(f"[DEBUG] summary ollama : Nettoyage : pas de balise trouv√©e")
        
        # Nettoyage des artefacts
        #summary = clean_summary(summary)
        
        return summary
    except OllamaError:
        logger.error("[ERROR] Import annul√©.")
    

def simplify_note_with_ai(content):
    logger.debug(f"[DEBUG] d√©marrage du simplify_note_with_ai")
    """
    Reformule et simplifie une note en utilisant Ollama.
    """
        
    prompt = PROMPTS["reformulation"].format(content=content)
    # Appel √† Ollama pour simplifier la note
    logger.debug(f"[DEBUG] simplify_note_with_ai : recherche et lancement du prompt")
    response = ollama_generate(prompt)
    
    return response.strip()

def enforce_titles(response):
    sections = re.split(r'\n(?=##|\n\n)', response)  # Split par titre Markdown ou paragraphes
    processed_sections = []
    for idx, section in enumerate(sections):
        if not section.startswith("TITLE:"):
            title = f"TITLE: Section {idx + 1}"  # Titre par d√©faut
            section = f"{title}\n{section.strip()}"
        processed_sections.append(section)
    return "\n\n".join(processed_sections)

def call_ollama_with_retry(prompt, model_ollama, retries=5, delay=100):
    """Appelle Ollama avec 3 essais avant d'abandonner."""
    logger.debug(f"[DEBUG] entr√©e call_ollama_with_retry model : {model_ollama}")
    for i in range(retries):
        try:
            return ollama_generate(prompt, model_ollama)  # üî• On essaie de contacter Ollama

        except OllamaError as e:
            logger.debug(f"[WARNING] Tentative {i+1}/{retries} √©chou√©e : {e}")
            if i < retries - 1:
                logger.info(f"[INFO] Nouvelle tentative dans {delay} secondes...")
                time.sleep(delay)
            else:
                logger.error("[ERREUR] Ollama ne r√©pond pas apr√®s plusieurs tentatives.")
                raise

# Traitement pour r√©ponse d'ollama
def ollama_generate(prompt, model_ollama):
    logger.debug(f"[DEBUG] entr√©e fonction : ollama_generate")
    ollama_url_generate = os.getenv('OLLAMA_URL_GENERATE')
    logger.debug(f"[DEBUG] ollama_generate, prompt : {prompt}")
    logger.debug(f"[DEBUG] ollama_generate, model_ollama : {model_ollama}")
    logger.debug(f"[DEBUG] ollama_generate, ollama_url_generate : {ollama_url_generate}")
        
    try:
    
        payload = {
            "model": model_ollama,
            "prompt": prompt,
            "options": {
                "num_predict": -1,
                "num_ctx": 8192
            }
        }
        
        response = requests.post(ollama_url_generate, json=payload, stream=True)
        logger.debug(f"[DEBUG] ollama_generate, response : {response}")
        
        if response.status_code == 200:
            full_response = ""
            for line in response.iter_lines():
                if line:
                    try:
                        json_line = json.loads(line)
                        full_response += json_line.get("response", "")
                        
                    except json.JSONDecodeError as e:
                        print(f"Erreur de d√©codage JSON : {e}")
            
            logger.debug(f"[DEBUG] ollama_generate, full_response : {full_response}")
            return full_response.strip()
        
        elif response.status_code in (500, 503):
                raise OllamaError("[ERREUR] Ollama semble plant√© ou indisponible.")

        elif response.status_code == 404:
            raise OllamaError("[ERREUR] Mod√®le introuvable sur Ollama.")

        else:
            raise OllamaError(f"[ERREUR] R√©ponse inattendue d'Ollama : {response.status_code}")

    except requests.exceptions.Timeout:
        raise OllamaError("[ERREUR] Ollama ne r√©pond pas (timeout).")

    except requests.exceptions.ConnectionError:
        raise OllamaError("[ERREUR] Impossible de se connecter √† Ollama (Docker HS ?).")